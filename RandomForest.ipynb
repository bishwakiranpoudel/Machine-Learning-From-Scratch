{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Random Forest \n",
    " Combines multiple decision trees ( ensemble method) to make robust predictions. Each tree is trained on a random subset of the data and features.\n",
    "\n",
    " ### Key Concepts \n",
    " Bagging: Randomly sampling subsets of data to train each tree.\n",
    " Feature Subset: Randomly selecting a subset of features for each tree to reduce overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=10):\n",
    "        self.max_depth = max_depth\n",
    "        self.tree = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.tree = self._build_tree(X, y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict(x, self.tree) for x in X])\n",
    "    \n",
    "    def _build_tree(self, X, y, depth=0):\n",
    "        # Stop criteria\n",
    "        if depth >= self.max_depth or len(set(y)) == 1:\n",
    "            return {'value': self._most_common_label(y)}\n",
    "        \n",
    "        # Find the best split\n",
    "        feature, threshold = self._best_split(X, y)\n",
    "        if feature is None:\n",
    "            return {'value': self._most_common_label(y)}\n",
    "        \n",
    "        # Split dataset\n",
    "        left_indices = X[:, feature] <= threshold\n",
    "        right_indices = X[:, feature] > threshold\n",
    "        left_child = self._build_tree(X[left_indices], y[left_indices], depth + 1)\n",
    "        right_child = self._build_tree(X[right_indices], y[right_indices], depth + 1)\n",
    "        \n",
    "        return {'feature': feature, 'threshold': threshold, 'left': left_child, 'right': right_child}\n",
    "    \n",
    "    def _best_split(self, X, y):\n",
    "        best_gain = -1\n",
    "        best_feature, best_threshold = None, None\n",
    "        current_entropy = self._entropy(y)\n",
    "        \n",
    "        for feature in range(X.shape[1]):\n",
    "            thresholds = np.unique(X[:, feature])\n",
    "            for threshold in thresholds:\n",
    "                left_indices = X[:, feature] <= threshold\n",
    "                right_indices = X[:, feature] > threshold\n",
    "                if len(y[left_indices]) == 0 or len(y[right_indices]) == 0:\n",
    "                    continue\n",
    "                \n",
    "                # Calculate Information Gain\n",
    "                left_entropy = self._entropy(y[left_indices])\n",
    "                right_entropy = self._entropy(y[right_indices])\n",
    "                left_weight = len(y[left_indices]) / len(y)\n",
    "                right_weight = len(y[right_indices]) / len(y)\n",
    "                gain = current_entropy - (left_weight * left_entropy + right_weight * right_entropy)\n",
    "                \n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    best_feature = feature\n",
    "                    best_threshold = threshold\n",
    "        \n",
    "        return best_feature, best_threshold\n",
    "    \n",
    "    def _entropy(self, y):\n",
    "        probabilities = np.bincount(y) / len(y)\n",
    "        return -np.sum([p * np.log2(p) for p in probabilities if p > 0])\n",
    "    \n",
    "    def _most_common_label(self, y):\n",
    "        return np.bincount(y).argmax()\n",
    "    \n",
    "    def _predict(self, x, tree):\n",
    "        if 'value' in tree:\n",
    "            return tree['value']\n",
    "        feature, threshold = tree['feature'], tree['threshold']\n",
    "        if x[feature] <= threshold:\n",
    "            return self._predict(x, tree['left'])\n",
    "        else:\n",
    "            return self._predict(x, tree['right'])\n",
    "\n",
    "\n",
    "class RandomForest:\n",
    "    def __init__(self, n_trees=10, max_depth=10, max_features=None):\n",
    "        self.n_trees = n_trees\n",
    "        self.max_depth = max_depth\n",
    "        self.max_features = max_features\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if self.max_features is None:\n",
    "            self.max_features = X.shape[1]  # Use all features if max_features is not specified\n",
    "\n",
    "        for _ in range(self.n_trees):\n",
    "            indices = np.random.choice(len(X), len(X), replace=True)\n",
    "            sample_X, sample_y = X[indices], y[indices]\n",
    "\n",
    "            features = np.random.choice(X.shape[1], self.max_features, replace=False)\n",
    "            tree = DecisionTree(max_depth=self.max_depth)\n",
    "            tree.fit(sample_X[:, features], sample_y)\n",
    "            self.trees.append((tree, features))\n",
    "\n",
    "    def predict(self, X):\n",
    "        tree_predictions = np.array([tree.predict(X[:, features]) for tree, features in self.trees])\n",
    "        return np.array([np.bincount(tree_predictions[:, i]).argmax() for i in range(X.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_iris()\n",
    "X, y= data.data, data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "model = RandomForest()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Random Forest Acurracy: {accuracy:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
